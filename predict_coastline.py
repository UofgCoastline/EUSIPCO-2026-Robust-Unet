#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ·æ°´åŒºåŸŸè¯­ä¹‰åˆ†å‰²é¢„æµ‹ä¸æµ·å²¸çº¿æå–ç¨‹åº
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ·æ°´åŒºåŸŸåˆ†å‰²å’Œæµ·å²¸çº¿æå–

ä½œè€…: CoastSatæµ·å²¸çº¿æå–åŠ©æ‰‹
åˆ›å»ºæ—¥æœŸ: 2025-01-26
"""

import os
import sys
import json
import numpy as np
import cv2
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
from matplotlib import gridspec
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from datetime import datetime
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from tkinter import Canvas, PhotoImage
from PIL import ImageTk
import threading
from osgeo import gdal
import warnings
import glob
warnings.filterwarnings('ignore')

class ZoomableImageCanvas(tk.Frame):
    """å¯ç¼©æ”¾å’Œæ‹–æ‹½çš„å›¾åƒCanvas"""
    
    def __init__(self, parent, image):
        """
        åˆå§‹åŒ–å¯ç¼©æ”¾å›¾åƒCanvas
        
        å‚æ•°:
        parent: çˆ¶çª—å£
        image: PIL.Image, è¦æ˜¾ç¤ºçš„å›¾åƒ
        """
        super().__init__(parent)
        
        # å›¾åƒç›¸å…³å˜é‡
        self.original_image = image
        self.current_image = image
        self.photo = None
        
        # ç¼©æ”¾å’Œæ‹–æ‹½ç›¸å…³å˜é‡
        self.scale_factor = 1.0
        self.min_scale = 0.1
        self.max_scale = 5.0
        self.drag_start_x = 0
        self.drag_start_y = 0
        self.is_dragging = False
        
        # åˆ›å»ºCanvaså’Œæ»šåŠ¨æ¡
        self.canvas = tk.Canvas(self, bg='white', highlightthickness=0)
        self.v_scrollbar = ttk.Scrollbar(self, orient=tk.VERTICAL, command=self.canvas.yview)
        self.h_scrollbar = ttk.Scrollbar(self, orient=tk.HORIZONTAL, command=self.canvas.xview)
        
        # é…ç½®Canvasæ»šåŠ¨
        self.canvas.configure(yscrollcommand=self.v_scrollbar.set, 
                            xscrollcommand=self.h_scrollbar.set)
        
        # å¸ƒå±€
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.v_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        self.h_scrollbar.pack(side=tk.BOTTOM, fill=tk.X)
        
        # ç»‘å®šäº‹ä»¶
        self.bind_events()
        
        # åˆå§‹æ˜¾ç¤ºå›¾åƒ
        self.update_image()
    
    def bind_events(self):
        """ç»‘å®šé¼ æ ‡å’Œé”®ç›˜äº‹ä»¶"""
        # é¼ æ ‡æ»šè½®ç¼©æ”¾
        self.canvas.bind("<MouseWheel>", self.on_mousewheel)
        self.canvas.bind("<Button-4>", self.on_mousewheel)  # Linux
        self.canvas.bind("<Button-5>", self.on_mousewheel)  # Linux
        
        # é¼ æ ‡æ‹–æ‹½
        self.canvas.bind("<ButtonPress-1>", self.on_drag_start)
        self.canvas.bind("<B1-Motion>", self.on_drag_motion)
        self.canvas.bind("<ButtonRelease-1>", self.on_drag_end)
        
        # é”®ç›˜å¿«æ·é”®
        self.canvas.bind("<Key>", self.on_key_press)
        self.canvas.focus_set()
        
        # åŒå‡»é‡ç½®ç¼©æ”¾
        self.canvas.bind("<Double-Button-1>", self.reset_zoom)
    
    def on_mousewheel(self, event):
        """å¤„ç†é¼ æ ‡æ»šè½®äº‹ä»¶"""
        # è·å–é¼ æ ‡ä½ç½®
        x = self.canvas.canvasx(event.x)
        y = self.canvas.canvasy(event.y)
        
        # è®¡ç®—ç¼©æ”¾å› å­
        if event.delta > 0 or event.num == 4:
            # å‘ä¸Šæ»šåŠ¨ï¼Œæ”¾å¤§
            scale = 1.1
        else:
            # å‘ä¸‹æ»šåŠ¨ï¼Œç¼©å°
            scale = 0.9
        
        # åº”ç”¨ç¼©æ”¾
        self.zoom_at_point(x, y, scale)
    
    def zoom_at_point(self, x, y, scale):
        """åœ¨æŒ‡å®šç‚¹è¿›è¡Œç¼©æ”¾"""
        new_scale = self.scale_factor * scale
        
        # é™åˆ¶ç¼©æ”¾èŒƒå›´
        if new_scale < self.min_scale:
            new_scale = self.min_scale
        elif new_scale > self.max_scale:
            new_scale = self.max_scale
        
        if new_scale == self.scale_factor:
            return
        
        # è®¡ç®—ç¼©æ”¾å‰åçš„ä½ç½®å·®
        scale_change = new_scale / self.scale_factor
        
        # æ›´æ–°ç¼©æ”¾å› å­
        self.scale_factor = new_scale
        
        # æ›´æ–°å›¾åƒ
        self.update_image()
        
        # è°ƒæ•´è§†å›¾ä½ç½®ä»¥ä¿æŒç¼©æ”¾ç‚¹å±…ä¸­
        canvas_width = self.canvas.winfo_width()
        canvas_height = self.canvas.winfo_height()
        
        if self.current_image.width > canvas_width:
            center_x = canvas_width / 2
            scroll_x = max(0, min(1, (x * scale_change - center_x) / (self.current_image.width - canvas_width)))
            self.canvas.xview_moveto(scroll_x)
        
        if self.current_image.height > canvas_height:
            center_y = canvas_height / 2
            scroll_y = max(0, min(1, (y * scale_change - center_y) / (self.current_image.height - canvas_height)))
            self.canvas.yview_moveto(scroll_y)
    
    def on_drag_start(self, event):
        """å¼€å§‹æ‹–æ‹½"""
        self.drag_start_x = event.x
        self.drag_start_y = event.y
        self.is_dragging = True
        self.canvas.configure(cursor="fleur")
        self.canvas.scan_mark(event.x, event.y)
    
    def on_drag_motion(self, event):
        """æ‹–æ‹½ç§»åŠ¨"""
        if not self.is_dragging:
            return
        
        # ä½¿ç”¨scan_dragtoå®ç°å¹³æ»‘æ‹–æ‹½
        self.canvas.scan_dragto(event.x, event.y, gain=1)
        
        # æ›´æ–°æ‹–æ‹½èµ·å§‹ç‚¹
        self.drag_start_x = event.x
        self.drag_start_y = event.y
    
    def on_drag_end(self, event):
        """ç»“æŸæ‹–æ‹½"""
        self.is_dragging = False
        self.canvas.configure(cursor="")
    
    def on_key_press(self, event):
        """å¤„ç†é”®ç›˜äº‹ä»¶"""
        if event.keysym == 'plus' or event.keysym == 'equal':
            # æ”¾å¤§
            self.zoom_at_center(1.1)
        elif event.keysym == 'minus':
            # ç¼©å°
            self.zoom_at_center(0.9)
        elif event.keysym == '0':
            # é‡ç½®ç¼©æ”¾
            self.reset_zoom()
    
    def zoom_at_center(self, scale):
        """åœ¨ä¸­å¿ƒç‚¹ç¼©æ”¾"""
        canvas_width = self.canvas.winfo_width()
        canvas_height = self.canvas.winfo_height()
        x = canvas_width / 2
        y = canvas_height / 2
        self.zoom_at_point(x, y, scale)
    
    def reset_zoom(self, event=None):
        """é‡ç½®ç¼©æ”¾åˆ°é€‚åˆçª—å£å¤§å°"""
        self.scale_factor = 1.0
        self.update_image()
        self.canvas.xview_moveto(0)
        self.canvas.yview_moveto(0)
    
    def update_image(self):
        """æ›´æ–°æ˜¾ç¤ºçš„å›¾åƒ"""
        # è®¡ç®—æ–°çš„å›¾åƒå°ºå¯¸
        new_width = int(self.original_image.width * self.scale_factor)
        new_height = int(self.original_image.height * self.scale_factor)
        
        # è°ƒæ•´å›¾åƒå¤§å°
        if self.scale_factor == 1.0:
            self.current_image = self.original_image
        else:
            # æ ¹æ®ç¼©æ”¾å› å­é€‰æ‹©åˆé€‚çš„é‡é‡‡æ ·æ–¹æ³•
            if self.scale_factor > 1.0:
                resample = Image.Resampling.LANCZOS
            else:
                resample = Image.Resampling.LANCZOS
            
            self.current_image = self.original_image.resize(
                (new_width, new_height), resample
            )
        
        # è½¬æ¢ä¸ºPhotoImage
        self.photo = ImageTk.PhotoImage(self.current_image)
        
        # æ¸…é™¤æ—§å›¾åƒ
        self.canvas.delete("image")
        
        # æ˜¾ç¤ºæ–°å›¾åƒ
        self.canvas.create_image(0, 0, anchor=tk.NW, image=self.photo, tags="image")
        
        # æ›´æ–°æ»šåŠ¨åŒºåŸŸ
        self.canvas.configure(scrollregion=self.canvas.bbox("all"))
    
    def fit_to_window(self):
        """é€‚åº”çª—å£å¤§å°"""
        canvas_width = self.canvas.winfo_width()
        canvas_height = self.canvas.winfo_height()
        
        if canvas_width <= 1 or canvas_height <= 1:
            return
        
        # è®¡ç®—é€‚åˆçª—å£çš„ç¼©æ”¾å› å­
        scale_x = canvas_width / self.original_image.width
        scale_y = canvas_height / self.original_image.height
        
        self.scale_factor = min(scale_x, scale_y, 1.0)  # ä¸æ”¾å¤§ï¼Œåªç¼©å°
        self.update_image()
        
        # å±…ä¸­æ˜¾ç¤º
        self.canvas.xview_moveto(0)
        self.canvas.yview_moveto(0)

class UNet(nn.Module):
    """U-Netè¯­ä¹‰åˆ†å‰²ç½‘ç»œ"""
    
    def __init__(self, n_channels=3, n_classes=2):
        """
        åˆå§‹åŒ–U-Net
        
        å‚æ•°:
        n_channels: int, è¾“å…¥é€šé“æ•°
        n_classes: int, åˆ†ç±»ç±»åˆ«æ•°
        """
        super(UNet, self).__init__()
        
        # ç¼–ç å™¨
        self.enc1 = self.conv_block(n_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.enc4 = self.conv_block(256, 512)
        
        # ç“¶é¢ˆå±‚
        self.bottleneck = self.conv_block(512, 1024)
        
        # è§£ç å™¨
        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec4 = self.conv_block(1024, 512)
        
        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(512, 256)
        
        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(256, 128)
        
        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(128, 64)
        
        # è¾“å‡ºå±‚
        self.final = nn.Conv2d(64, n_classes, kernel_size=1)
        
        # æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
    
    def conv_block(self, in_channels, out_channels):
        """å·ç§¯å—"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # ç¼–ç è·¯å¾„
        enc1 = self.enc1(x)
        enc2 = self.enc2(self.pool(enc1))
        enc3 = self.enc3(self.pool(enc2))
        enc4 = self.enc4(self.pool(enc3))
        
        # ç“¶é¢ˆ
        bottleneck = self.bottleneck(self.pool(enc4))
        
        # è§£ç è·¯å¾„
        dec4 = self.upconv4(bottleneck)
        dec4 = torch.cat([dec4, enc4], dim=1)
        dec4 = self.dec4(dec4)
        
        dec3 = self.upconv3(dec4)
        dec3 = torch.cat([dec3, enc3], dim=1)
        dec3 = self.dec3(dec3)
        
        dec2 = self.upconv2(dec3)
        dec2 = torch.cat([dec2, enc2], dim=1)
        dec2 = self.dec2(dec2)
        
        dec1 = self.upconv1(dec2)
        dec1 = torch.cat([dec1, enc1], dim=1)
        dec1 = self.dec1(dec1)
        
        return self.final(dec1)

class CoastlineExtractor:
    """æµ·å²¸çº¿æå–å™¨"""
    
    def __init__(self, model_path=None, device='cpu'):
        """
        åˆå§‹åŒ–æµ·å²¸çº¿æå–å™¨
        
        å‚æ•°:
        model_path: str, è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
        device: str, è®¡ç®—è®¾å¤‡
        """
        self.device = device
        self.model = UNet(n_channels=3, n_classes=2)
        
        if model_path and os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location=device))
            print(f"å·²åŠ è½½æ¨¡å‹: {model_path}")
        
        self.model.to(device)
        self.model.eval()
        
        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225])
        ])
    
    def extract_coastline_from_image(self, image_path, output_dir=None, dilation_size=5):
        """
        ä»å•å¼ å›¾åƒæå–æµ·å²¸çº¿ï¼ˆæ”¯æŒTIFæ ¼å¼ï¼‰
        
        å‚æ•°:
        image_path: str, å›¾åƒè·¯å¾„
        output_dir: str, è¾“å‡ºç›®å½•
        dilation_size: int, è†¨èƒ€æ“ä½œæ ¸å¤§å°
        
        è¿”å›:
        dict: æµ·å²¸çº¿æå–ç»“æœ
        """
        try:
            # è¯»å–å›¾åƒï¼ˆæ”¯æŒTIFæ ¼å¼ï¼‰
            if image_path.lower().endswith(('.tif', '.tiff')):
                image = self.load_tif_image(image_path)
            else:
                image = Image.open(image_path).convert('RGB')
            
            original_size = image.size
            
            # é¢„å¤„ç†
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                output = self.model(input_tensor)
                pred_mask = torch.argmax(output, dim=1).cpu().numpy()[0]
            
            # è°ƒæ•´maskå°ºå¯¸åˆ°åŸå›¾å¤§å°
            pred_mask_resized = cv2.resize(pred_mask.astype(np.uint8), 
                                         original_size, interpolation=cv2.INTER_NEAREST)
            
            # æå–æµ·å²¸çº¿è½®å»“ï¼ˆä½¿ç”¨è†¨èƒ€æ“ä½œï¼‰
            coastlines, coastline_mask = self.extract_coastline_contours(
                pred_mask_resized, dilation_kernel_size=dilation_size
            )
            
            # åˆ›å»ºç»“æœ
            result = {
                'image_path': image_path,
                'image_size': original_size,
                'water_mask': pred_mask_resized,
                'coastline_mask': coastline_mask,
                'coastlines': coastlines,
                'coastline_count': len(coastlines),
                'dilation_size': dilation_size,
                'extraction_time': str(datetime.now())
            }
            
            # ä¿å­˜ç»“æœ
            if output_dir:
                self.save_extraction_result(result, output_dir)
            
            return result
            
        except Exception as e:
            print(f"æå–æµ·å²¸çº¿æ—¶å‡ºé”™ {image_path}: {e}")
            return None
    
    def load_tif_image(self, tif_path):
        """
        åŠ è½½TIFæ ¼å¼å›¾åƒï¼ˆä¸tif_to_image.pyå’Œè®­ç»ƒç¨‹åºä¿æŒä¸€è‡´çš„æ°´ä½“å¢å¼ºï¼‰
        ç”¨äºæ¨¡å‹é¢„æµ‹
        
        å‚æ•°:
        tif_path: str, TIFæ–‡ä»¶è·¯å¾„
        
        è¿”å›:
        PIL.Image: RGBå›¾åƒ
        """
        try:
            dataset = gdal.Open(tif_path)
            if dataset is None:
                raise ValueError(f"æ— æ³•æ‰“å¼€TIFæ–‡ä»¶: {tif_path}")
            
            # è¯»å–æ³¢æ®µæ•°æ®ï¼ˆä¸è½¬æ¢ç¨‹åºä¿æŒä¸€è‡´ï¼‰
            bands = []
            for i in range(1, min(dataset.RasterCount + 1, 7)):  # æœ€å¤šè¯»å–6ä¸ªæ³¢æ®µ
                band = dataset.GetRasterBand(i)
                data = band.ReadAsArray()
                bands.append(data)
            
            bands = np.array(bands)
            
            # åˆ›å»ºRGBå›¾åƒï¼ˆä¸tif_to_image.pyçš„é€»è¾‘ä¸€è‡´ï¼‰
            if bands.shape[0] >= 3:
                if bands.shape[0] >= 4:
                    # ä½¿ç”¨NIR-Red-Greenç»„åˆçªå‡ºæ°´ä½“ï¼ˆä¸è½¬æ¢ç¨‹åºä¸€è‡´ï¼‰
                    try:
                        rgb = np.dstack([bands[4], bands[3], bands[2]])  # NIR, Red, Green
                    except IndexError:
                        rgb = np.dstack([bands[2], bands[1], bands[0]])  # æ ‡å‡†RGB
                else:
                    rgb = np.dstack([bands[2], bands[1], bands[0]])  # Red, Green, Blue
            else:
                # ç°åº¦å›¾åƒ
                gray = bands[0]
                rgb = np.dstack([gray, gray, gray])
            
            # å›¾åƒå¢å¼ºï¼ˆä¸è½¬æ¢ç¨‹åºä¸€è‡´ï¼‰
            rgb_enhanced = self.enhance_image_for_water(rgb)
            return Image.fromarray(rgb_enhanced.astype(np.uint8))
            
        except Exception as e:
            print(f"åŠ è½½TIFå›¾åƒå¤±è´¥ {tif_path}: {e}")
            return Image.new('RGB', (512, 512), (0, 0, 0))
    
    def load_tif_image_for_display(self, tif_path):
        """
        åŠ è½½TIFæ ¼å¼å›¾åƒç”¨äºGUIæ˜¾ç¤ºï¼ˆä¸åº”ç”¨æ°´ä½“å¢å¼ºï¼‰
        
        å‚æ•°:
        tif_path: str, TIFæ–‡ä»¶è·¯å¾„
        
        è¿”å›:
        PIL.Image: RGBå›¾åƒï¼ˆåŸå§‹æ˜¾ç¤ºæ•ˆæœï¼‰
        """
        try:
            dataset = gdal.Open(tif_path)
            if dataset is None:
                raise ValueError(f"æ— æ³•æ‰“å¼€TIFæ–‡ä»¶: {tif_path}")
            
            # è¯»å–æ³¢æ®µæ•°æ®
            bands = []
            for i in range(1, min(dataset.RasterCount + 1, 7)):  # æœ€å¤šè¯»å–6ä¸ªæ³¢æ®µ
                band = dataset.GetRasterBand(i)
                data = band.ReadAsArray()
                bands.append(data)
            
            bands = np.array(bands)
            
            # åˆ›å»ºRGBå›¾åƒï¼ˆæ ‡å‡†RGBç»„åˆç”¨äºè‡ªç„¶æ˜¾ç¤ºï¼‰
            if bands.shape[0] >= 3:
                # ä½¿ç”¨æ ‡å‡†å‰ä¸‰ä¸ªæ³¢æ®µä½œä¸ºRGBï¼ˆé€šå¸¸å‰ä¸‰ä¸ªæ³¢æ®µæ˜¯RGBï¼‰
                rgb = np.dstack([bands[0], bands[1], bands[2]])  # æ ‡å‡†RGBé¡ºåº
            else:
                # ç°åº¦å›¾åƒ
                gray = bands[0]
                rgb = np.dstack([gray, gray, gray])
            
            # æ ‡å‡†å½’ä¸€åŒ–ï¼ˆä¸åº”ç”¨æ°´ä½“å¢å¼ºï¼‰
            rgb_normalized = self.normalize_image_for_display(rgb)
            return Image.fromarray(rgb_normalized.astype(np.uint8))
            
        except Exception as e:
            print(f"åŠ è½½TIFå›¾åƒå¤±è´¥ {tif_path}: {e}")
            return Image.new('RGB', (512, 512), (0, 0, 0))
    
    def normalize_image_for_display(self, rgb):
        """
        æ–¹æ³•1_æ ‡å‡†RGBçš„å›¾åƒå½’ä¸€åŒ–ç”¨äºæ˜¾ç¤ºï¼ˆä¸åº”ç”¨æ°´ä½“å¢å¼ºï¼‰
        é‡‡ç”¨ç®€å•çº¿æ€§æ‹‰ä¼¸æ–¹å¼ï¼Œä¿æŒæœ€è‡ªç„¶çš„æ˜¾ç¤ºæ•ˆæœ
        
        å‚æ•°:
        rgb: numpy.ndarray, RGBå›¾åƒæ•°ç»„
        
        è¿”å›:
        numpy.ndarray: å½’ä¸€åŒ–åçš„å›¾åƒ
        """
        # ç¡®ä¿è¾“å…¥æ˜¯3é€šé“RGBå›¾åƒ
        if rgb.shape[2] < 3:
            # ç°åº¦å›¾åƒæ‰©å±•ä¸ºRGB
            gray = rgb[:, :, 0]
            processed_rgb = np.dstack([gray, gray, gray])
        else:
            # ä½¿ç”¨ç°æœ‰çš„RGBæ•°æ®ï¼ˆåªå–å‰3ä¸ªé€šé“ï¼‰
            processed_rgb = rgb[:, :, :3].copy()
        
        # ç®€å•çº¿æ€§æ‹‰ä¼¸ï¼ˆä¸æµ‹è¯•ç¨‹åºæ–¹æ³•1å®Œå…¨ä¸€è‡´ï¼‰
        normalized = np.zeros_like(processed_rgb)
        for i in range(3):  # åªå¤„ç†RGBä¸‰ä¸ªé€šé“
            band = processed_rgb[:, :, i].astype(np.float64)
            
            # è®¡ç®—ç™¾åˆ†ä½æ•°è¿›è¡Œæ‹‰ä¼¸
            p2, p98 = np.percentile(band, [2, 98])
            
            # é¿å…é™¤é›¶é”™è¯¯
            if p98 - p2 > 0:
                band_stretched = np.clip((band - p2) / (p98 - p2) * 255, 0, 255)
            else:
                band_stretched = np.clip(band, 0, 255)
            
            normalized[:, :, i] = band_stretched
        
        return normalized
    
    def enhance_image_for_water(self, rgb):
        """
        å¢å¼ºå›¾åƒå¯¹æ¯”åº¦ï¼Œçªå‡ºæ°´ä½“åŒºåŸŸï¼ˆä¸tif_to_image.pyå’Œè®­ç»ƒç¨‹åºä¿æŒä¸€è‡´ï¼‰
        
        å‚æ•°:
        rgb: numpy.ndarray, RGBå›¾åƒæ•°ç»„
        
        è¿”å›:
        numpy.ndarray: å¢å¼ºåçš„å›¾åƒ
        """
        enhanced = np.zeros_like(rgb)
        
        for i in range(rgb.shape[2]):
            band = rgb[:, :, i]
            
            # è®¡ç®—ç™¾åˆ†ä½æ•°è¿›è¡Œæ‹‰ä¼¸
            p2, p98 = np.percentile(band, [2, 98])
            
            # çº¿æ€§æ‹‰ä¼¸
            band_stretched = np.clip((band - p2) / (p98 - p2) * 255, 0, 255)
            
            # å¯¹æ°´ä½“åŒºåŸŸè¿›è¡Œé¢å¤–å¢å¼º
            if i == 0:  # å‡è®¾ç¬¬ä¸€ä¸ªæ³¢æ®µæ˜¯è¿‘çº¢å¤–æˆ–çº¢è‰²
                # å¢å¼ºä½å€¼åŒºåŸŸï¼ˆå¯èƒ½æ˜¯æ°´ä½“ï¼‰
                mask = band_stretched < 100
                band_stretched[mask] = band_stretched[mask] * 0.7  # é™ä½äº®åº¦çªå‡ºæ°´ä½“
            
            enhanced[:, :, i] = band_stretched
        
        return enhanced
    
    def extract_coastline_contours(self, water_mask, dilation_kernel_size=5):
        """
        ä»æ°´ä½“maskæå–æµ·å²¸çº¿è½®å»“ï¼ˆä½¿ç”¨è†¨èƒ€æ“ä½œï¼‰
        
        å‚æ•°:
        water_mask: numpy.ndarray, æ°´ä½“åˆ†å‰²mask
        dilation_kernel_size: int, è†¨èƒ€æ“ä½œæ ¸å¤§å°
        
        è¿”å›:
        tuple: (coastlines, dilated_mask) æµ·å²¸çº¿è½®å»“ç‚¹åˆ—è¡¨å’Œè†¨èƒ€åçš„mask
        """
        # åˆ›å»ºè†¨èƒ€æ ¸
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, 
                                         (dilation_kernel_size, dilation_kernel_size))
        
        # å¯¹æ°´ä½“åŒºåŸŸè¿›è¡Œè†¨èƒ€æ“ä½œ
        dilated_mask = cv2.dilate(water_mask, kernel, iterations=1)
        
        # è®¡ç®—è†¨èƒ€åŒºåŸŸçš„è¾¹ç•Œï¼ˆè†¨èƒ€åçš„åŒºåŸŸå‡å»åŸå§‹åŒºåŸŸï¼‰
        coastline_mask = dilated_mask - water_mask
        
        # æŸ¥æ‰¾æµ·å²¸çº¿è½®å»“
        contours, _ = cv2.findContours(coastline_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        coastlines = []
        for contour in contours:
            if len(contour) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è½®å»“
                # ç®€åŒ–è½®å»“
                epsilon = 0.002 * cv2.arcLength(contour, True)
                simplified = cv2.approxPolyDP(contour, epsilon, True)
                
                # è½¬æ¢ä¸ºç‚¹åˆ—è¡¨
                points = simplified.reshape(-1, 2).tolist()
                coastlines.append(points)
        
        return coastlines, coastline_mask
    
    def save_extraction_result(self, result, output_dir):
        """
        ä¿å­˜æµ·å²¸çº¿æå–ç»“æœ
        
        å‚æ•°:
        result: dict, æå–ç»“æœ
        output_dir: str, è¾“å‡ºç›®å½•
        """
        os.makedirs(output_dir, exist_ok=True)
        
        base_name = os.path.splitext(os.path.basename(result['image_path']))[0]
        
        # ä¿å­˜æ°´ä½“mask
        water_mask_path = os.path.join(output_dir, f"{base_name}_water_mask.png")
        Image.fromarray(result['water_mask'] * 255).save(water_mask_path)
        
        # ä¿å­˜æµ·å²¸çº¿mask
        coastline_mask_path = os.path.join(output_dir, f"{base_name}_coastline_mask.png")
        Image.fromarray(result['coastline_mask'] * 255).save(coastline_mask_path)
        
        # ä¿å­˜æµ·å²¸çº¿æ•°æ®
        coastline_path = os.path.join(output_dir, f"{base_name}_coastlines.json")
        coastline_data = {
            'image_path': result['image_path'],
            'image_size': result['image_size'],
            'coastlines': result['coastlines'],
            'coastline_count': result['coastline_count'],
            'dilation_size': result.get('dilation_size', 5),
            'extraction_time': result['extraction_time']
        }
        
        with open(coastline_path, 'w', encoding='utf-8') as f:
            json.dump(coastline_data, f, indent=2, ensure_ascii=False)
        
        # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
        self.create_coastsat_style_visualization(result, output_dir)
        
        print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
    
    def create_coastsat_style_visualization(self, result, output_dir):
        """
        åˆ›å»ºCoastSaté£æ ¼çš„æµ·å²¸çº¿å¯è§†åŒ–
        
        å‚æ•°:
        result: dict, æå–ç»“æœ
        output_dir: str, è¾“å‡ºç›®å½•
        """
        # è¯»å–åŸå›¾ï¼ˆç”¨äºæ˜¾ç¤ºï¼Œä¸åº”ç”¨æ°´ä½“å¢å¼ºï¼‰
        if result['image_path'].lower().endswith(('.tif', '.tiff')):
            image = self.load_tif_image_for_display(result['image_path'])
        else:
            image = Image.open(result['image_path'])
        
        # åˆ›å»ºCoastSaté£æ ¼çš„å¤šé¢æ¿æ˜¾ç¤º
        fig = plt.figure(figsize=(20, 12))
        gs = gridspec.GridSpec(3, 4, hspace=0.3, wspace=0.3)
        
        # ä¸»å›¾ï¼šåŸå›¾ + æµ·å²¸çº¿å åŠ 
        ax_main = fig.add_subplot(gs[:2, :2])
        ax_main.imshow(image)
        
        # å åŠ æµ·å²¸çº¿ï¼ˆCoastSatçº¢è‰²é£æ ¼ï¼‰
        for i, coastline in enumerate(result['coastlines']):
            if len(coastline) > 2:
                coastline_array = np.array(coastline)
                ax_main.plot(coastline_array[:, 0], coastline_array[:, 1], 
                           'r-', linewidth=3, alpha=0.8, label=f'æµ·å²¸çº¿ {i+1}' if i < 3 else '')
        
        ax_main.set_title(f'æµ·å²¸çº¿æ£€æµ‹ç»“æœ\\n{os.path.basename(result["image_path"])}', 
                         fontsize=16, fontweight='bold')
        ax_main.axis('off')
        if len(result['coastlines']) <= 3:
            ax_main.legend(loc='upper right')
        
        # æ°´ä½“åˆ†å‰²ç»“æœï¼ˆè“è‰²ï¼‰
        ax_water = fig.add_subplot(gs[0, 2])
        water_colored = np.zeros((*result['water_mask'].shape, 3))
        water_colored[result['water_mask'] == 1] = [0, 0.4, 0.8]  # æ·±è“è‰²
        ax_water.imshow(water_colored)
        ax_water.set_title('æ°´ä½“åŒºåŸŸ\\n(è“è‰²)', fontsize=12, fontweight='bold')
        ax_water.axis('off')
        
        # æµ·å²¸çº¿maskï¼ˆç™½è‰²ï¼‰
        ax_coast = fig.add_subplot(gs[0, 3])
        ax_coast.imshow(result['coastline_mask'], cmap='gray')
        ax_coast.set_title('æµ·å²¸çº¿åŒºåŸŸ\\n(ç™½è‰²)', fontsize=12, fontweight='bold')
        ax_coast.axis('off')
        
        # ç»¼åˆå åŠ å›¾
        ax_combined = fig.add_subplot(gs[1, 2])
        combined_img = np.array(image.copy())
        
        # è°ƒæ•´å°ºå¯¸
        display_size = combined_img.shape[:2][::-1]  # (width, height)
        water_mask_resized = cv2.resize(result['water_mask'].astype(np.uint8), 
                                      display_size, interpolation=cv2.INTER_NEAREST)
        coastline_mask_resized = cv2.resize(result['coastline_mask'].astype(np.uint8), 
                                          display_size, interpolation=cv2.INTER_NEAREST)
        
        # æ°´ä½“åŠé€æ˜å åŠ 
        water_coords = np.where(water_mask_resized == 1)
        if len(water_coords[0]) > 0:
            combined_img[water_coords[0], water_coords[1]] = \
                combined_img[water_coords[0], water_coords[1]] * 0.6 + np.array([0, 100, 200]) * 0.4
        
        # æµ·å²¸çº¿ç™½è‰²å åŠ 
        coastline_coords = np.where(coastline_mask_resized == 1)
        if len(coastline_coords[0]) > 0:
            combined_img[coastline_coords[0], coastline_coords[1]] = [255, 255, 255]
        
        ax_combined.imshow(combined_img.astype(np.uint8))
        ax_combined.set_title('ç»¼åˆç»“æœ', fontsize=12, fontweight='bold')
        ax_combined.axis('off')
        
        # ç»Ÿè®¡ä¿¡æ¯é¢æ¿
        ax_stats = fig.add_subplot(gs[1, 3])
        ax_stats.axis('off')
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_pixels = result['water_mask'].size
        water_pixels = np.sum(result['water_mask'])
        coastline_pixels = np.sum(result['coastline_mask'])
        water_ratio = water_pixels / total_pixels * 100
        
        stats_text = f"""
        ğŸ“Š æ£€æµ‹ç»Ÿè®¡
        
        å›¾åƒå°ºå¯¸: {result['image_size'][0]} Ã— {result['image_size'][1]}
        æ€»åƒç´ æ•°: {total_pixels:,}
        æ°´ä½“åƒç´ : {water_pixels:,}
        æµ·å²¸çº¿åƒç´ : {coastline_pixels:,}
        æ°´ä½“å æ¯”: {water_ratio:.1f}%
        æµ·å²¸çº¿æ•°é‡: {result['coastline_count']}
        è†¨èƒ€æ ¸å¤§å°: {result.get('dilation_size', 5)}
        å¤„ç†æ—¶é—´: {result['extraction_time'][:19]}
        """
        
        ax_stats.text(0.05, 0.95, stats_text, fontsize=10, verticalalignment='top',
                     bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
        
        # æµ·å²¸çº¿é•¿åº¦åˆ†æ
        ax_length = fig.add_subplot(gs[2, :2])
        if result['coastlines']:
            coastline_lengths = []
            for coastline in result['coastlines']:
                if len(coastline) > 1:
                    # è®¡ç®—æµ·å²¸çº¿é•¿åº¦ï¼ˆåƒç´ å•ä½ï¼‰
                    points = np.array(coastline)
                    distances = np.sqrt(np.sum(np.diff(points, axis=0)**2, axis=1))
                    total_length = np.sum(distances)
                    coastline_lengths.append(total_length)
            
            if coastline_lengths:
                ax_length.bar(range(1, len(coastline_lengths)+1), coastline_lengths, 
                            color='coral', alpha=0.7, edgecolor='red')
                ax_length.set_xlabel('æµ·å²¸çº¿ç¼–å·')
                ax_length.set_ylabel('é•¿åº¦ (åƒç´ )')
                ax_length.set_title('å„æµ·å²¸çº¿é•¿åº¦åˆ†å¸ƒ', fontsize=12, fontweight='bold')
                ax_length.grid(True, alpha=0.3)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, length in enumerate(coastline_lengths):
                    ax_length.text(i+1, length + max(coastline_lengths)*0.01, 
                                  f'{length:.0f}', ha='center', va='bottom', fontsize=9)
        
        # æ°´ä½“åˆ†å¸ƒç›´æ–¹å›¾
        ax_hist = fig.add_subplot(gs[2, 2:])
        
        # åˆ›å»ºNDWIæŒ‡æ•°ç”¨äºåˆ†æï¼ˆå¦‚æœæ˜¯å¤šå…‰è°±å›¾åƒï¼‰
        try:
            if result['image_path'].lower().endswith(('.tif', '.tiff')):
                # å¯¹äºTIFå›¾åƒï¼Œå°è¯•è®¡ç®—NDWI
                dataset = gdal.Open(result['image_path'])
                if dataset and dataset.RasterCount >= 4:
                    # è¯»å–NIRå’ŒGreenæ³¢æ®µ
                    nir_band = dataset.GetRasterBand(4).ReadAsArray()
                    green_band = dataset.GetRasterBand(2).ReadAsArray()
                    
                    # è®¡ç®—NDWI
                    ndwi = (green_band.astype(float) - nir_band.astype(float)) / \
                           (green_band.astype(float) + nir_band.astype(float) + 1e-8)
                    
                    # åªæ˜¾ç¤ºæ°´ä½“åŒºåŸŸçš„NDWIå€¼
                    water_ndwi = ndwi[result['water_mask'] == 1]
                    other_ndwi = ndwi[result['water_mask'] == 0]
                    
                    ax_hist.hist(other_ndwi.flatten(), bins=50, alpha=0.5, color='brown', 
                               label='éæ°´ä½“', density=True)
                    ax_hist.hist(water_ndwi.flatten(), bins=50, alpha=0.7, color='blue', 
                               label='æ°´ä½“', density=True)
                    ax_hist.set_xlabel('NDWIå€¼')
                    ax_hist.set_ylabel('å¯†åº¦')
                    ax_hist.set_title('æ°´ä½“æŒ‡æ•°(NDWI)åˆ†å¸ƒ', fontsize=12, fontweight='bold')
                    ax_hist.legend()
                    ax_hist.grid(True, alpha=0.3)
                else:
                    raise Exception("æ— æ³•è®¡ç®—NDWI")
            else:
                raise Exception("éTIFæ ¼å¼")
                
        except:
            # å¦‚æœæ— æ³•è®¡ç®—NDWIï¼Œæ˜¾ç¤ºåƒç´ å¼ºåº¦åˆ†å¸ƒ
            img_array = np.array(image)
            
            # RGBé€šé“åˆ†æ
            colors = ['red', 'green', 'blue']
            for i, color in enumerate(colors):
                channel_values = img_array[:, :, i].flatten()
                ax_hist.hist(channel_values, bins=50, alpha=0.5, color=color, 
                           label=f'{color.upper()}é€šé“', density=True)
            
            ax_hist.set_xlabel('åƒç´ å€¼')
            ax_hist.set_ylabel('å¯†åº¦')
            ax_hist.set_title('RGBé€šé“å¼ºåº¦åˆ†å¸ƒ', fontsize=12, fontweight='bold')
            ax_hist.legend()
            ax_hist.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•´ä½“æ ‡é¢˜
        fig.suptitle('ğŸŒŠ CoastSaté£æ ¼æµ·å²¸çº¿æå–åˆ†ææŠ¥å‘Š', fontsize=20, fontweight='bold', y=0.98)
        
        # ä¿å­˜å›¾åƒ
        base_name = os.path.splitext(os.path.basename(result['image_path']))[0]
        viz_path = os.path.join(output_dir, f"{base_name}_coastsat_analysis.png")
        plt.savefig(viz_path, dpi=200, bbox_inches='tight')
        plt.close()
        
        return viz_path

class CoastlineGUI:
    """æµ·æ°´åŒºåŸŸåˆ†å‰²ä¸æµ·å²¸çº¿æå–ç³»ç»Ÿ - ç°ä»£åŒ–å·¥ä¸šç•Œé¢"""
    
    def __init__(self, root):
        """
        åˆå§‹åŒ–GUI
        
        å‚æ•°:
        root: tk.Tk, ä¸»çª—å£
        """
        self.root = root
        self.root.title("ğŸŒŠ æµ·æ°´åŒºåŸŸåˆ†å‰²ä¸æµ·å²¸çº¿æå–ç³»ç»Ÿ v2.0")
        self.root.geometry("1400x900")
        self.root.configure(bg='#f0f0f0')
        
        # è®¾ç½®ç°ä»£åŒ–ä¸»é¢˜
        self.setup_styles()
        
        # åˆå§‹åŒ–å˜é‡
        self.model_path = tk.StringVar()
        self.image_paths = []  # æ”¯æŒå¤šå¼ å›¾ç‰‡
        self.current_image_index = 0
        self.dilation_size = 20  # é»˜è®¤è†¨èƒ€æ ¸å¤§å°ä¸º20
        self.extractor = None
        self.current_results = []  # å­˜å‚¨å¤šä¸ªç»“æœ
        self.is_batch_mode = False
        
        self.setup_ui()
        
        # è‡ªåŠ¨åŠ è½½é»˜è®¤æ¨¡å‹
        self.auto_load_default_model()
    
    def setup_styles(self):
        """è®¾ç½®ç°ä»£åŒ–ç•Œé¢é£æ ¼"""
        self.style = ttk.Style()
        
        # é…ç½®ç°ä»£åŒ–é¢œè‰²ä¸»é¢˜
        self.colors = {
            'primary': '#2196F3',      # è“è‰²
            'primary_dark': '#1976D2',
            'secondary': '#FF9800',    # æ©™è‰²
            'success': '#4CAF50',      # ç»¿è‰²
            'warning': '#FF5722',      # çº¢æ©™è‰²
            'info': '#00BCD4',         # é’è‰²
            'light': '#F5F5F5',        # æµ…ç°
            'dark': '#424242',         # æ·±ç°
            'white': '#FFFFFF'
        }
        
        # è®¾ç½®ttkæ ·å¼
        self.style.theme_use('clam')
        
        # é…ç½®æŒ‰é’®æ ·å¼
        self.style.configure('Primary.TButton', 
                           background=self.colors['primary'],
                           foreground='white',
                           font=('Microsoft YaHei', 10, 'bold'),
                           relief='flat',
                           borderwidth=0,
                           focuscolor='none')
        
        self.style.configure('Success.TButton',
                           background=self.colors['success'],
                           foreground='white',
                           font=('Microsoft YaHei', 10, 'bold'),
                           relief='flat',
                           borderwidth=0)
        
        self.style.configure('Warning.TButton',
                           background=self.colors['warning'],
                           foreground='white',
                           font=('Microsoft YaHei', 10, 'bold'),
                           relief='flat',
                           borderwidth=0)
        
        # é…ç½®æ ‡ç­¾æ¡†æ ·å¼
        self.style.configure('Modern.TLabelframe',
                           background='white',
                           borderwidth=1,
                           relief='solid')
        
        self.style.configure('Modern.TLabelframe.Label',
                           background='white',
                           foreground=self.colors['primary'],
                           font=('Microsoft YaHei', 11, 'bold'))
    
    def auto_load_default_model(self):
        """è‡ªåŠ¨åŠ è½½é»˜è®¤æ¨¡å‹"""
        default_model_path = "./models/best_water_segmentation_model.pth"
        if os.path.exists(default_model_path):
            self.model_path.set(default_model_path)
            self.load_model_silent()
    
    def load_model_silent(self):
        """é™é»˜åŠ è½½æ¨¡å‹ï¼ˆä¸å¼¹çª—æç¤ºï¼‰"""
        if not self.model_path.get():
            return
        
        try:
            self.status_var.set("æ­£åœ¨åŠ è½½æ¨¡å‹...")
            self.root.update()
            
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.extractor = CoastlineExtractor(self.model_path.get(), device=device)
            
            print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path.get()}")
            print(f"âœ“ ä½¿ç”¨è®¾å¤‡: {device}")
            self.status_var.set(f"æ¨¡å‹å·²å°±ç»ª (è®¾å¤‡: {device}) | è†¨èƒ€æ ¸å¤§å°: {self.dilation_size}")
            self.model_status_label.config(text="âœ“ å·²åŠ è½½", foreground=self.colors['success'])
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            self.status_var.set("æ¨¡å‹åŠ è½½å¤±è´¥")
            self.model_status_label.config(text="âŒ å¤±è´¥", foreground=self.colors['warning'])

    def setup_ui(self):
        """è®¾ç½®ç°ä»£åŒ–ç”¨æˆ·ç•Œé¢"""
        # ä¸»å®¹å™¨
        main_container = tk.Frame(self.root, bg='#f0f0f0')
        main_container.pack(fill=tk.BOTH, expand=True, padx=15, pady=15)
        
        # é¡¶éƒ¨æ ‡é¢˜æ 
        self.create_header(main_container)
        
        # æ§åˆ¶é¢æ¿åŒºåŸŸ
        self.create_control_panel(main_container)
        
        # å›¾åƒåˆ—è¡¨å’Œé¢„è§ˆåŒºåŸŸ
        self.create_image_panel(main_container)
        
        # ç»“æœæ˜¾ç¤ºåŒºåŸŸ
        self.create_results_panel(main_container)
        
        # åº•éƒ¨çŠ¶æ€æ 
        self.create_status_bar(main_container)
    
    def create_header(self, parent):
        """åˆ›å»ºé¡¶éƒ¨æ ‡é¢˜æ """
        header_frame = tk.Frame(parent, bg=self.colors['primary'], height=80)
        header_frame.pack(fill=tk.X, pady=(0, 15))
        header_frame.pack_propagate(False)
        
        # æ ‡é¢˜
        title_label = tk.Label(header_frame, 
                              text="ğŸŒŠ æµ·æ°´åŒºåŸŸåˆ†å‰²ä¸æµ·å²¸çº¿æå–ç³»ç»Ÿ",
                              bg=self.colors['primary'],
                              fg='white',
                              font=('Microsoft YaHei', 18, 'bold'))
        title_label.pack(side=tk.LEFT, padx=20, pady=20)
        
        # ç‰ˆæœ¬ä¿¡æ¯
        version_label = tk.Label(header_frame,
                                text="v2.0 | CoastSat Enhanced",
                                bg=self.colors['primary'],
                                fg='white',
                                font=('Microsoft YaHei', 10))
        version_label.pack(side=tk.RIGHT, padx=20, pady=20)
    
    def create_control_panel(self, parent):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        control_frame = ttk.LabelFrame(parent, text="ğŸ”§ æ§åˆ¶é¢æ¿", style='Modern.TLabelframe', padding=15)
        control_frame.pack(fill=tk.X, pady=(0, 15))
        
        # ç¬¬ä¸€è¡Œï¼šæ¨¡å‹é…ç½®
        model_row = tk.Frame(control_frame, bg='white')
        model_row.pack(fill=tk.X, pady=5)
        
        tk.Label(model_row, text="ğŸ¤– æ¨¡å‹:", bg='white', font=('Microsoft YaHei', 10, 'bold')).pack(side=tk.LEFT)
        model_entry = ttk.Entry(model_row, textvariable=self.model_path, width=45, font=('Consolas', 9))
        model_entry.pack(side=tk.LEFT, padx=10)
        
        ttk.Button(model_row, text="ğŸ“ é€‰æ‹©", command=self.select_model).pack(side=tk.LEFT, padx=5)
        ttk.Button(model_row, text="âš¡ åŠ è½½", command=self.load_model, style='Primary.TButton').pack(side=tk.LEFT, padx=5)
        
        self.model_status_label = tk.Label(model_row, text="â³ æœªåŠ è½½", bg='white', font=('Microsoft YaHei', 9))
        self.model_status_label.pack(side=tk.LEFT, padx=10)
        
        # ç¬¬äºŒè¡Œï¼šå›¾åƒé…ç½®
        image_row = tk.Frame(control_frame, bg='white')
        image_row.pack(fill=tk.X, pady=10)
        
        tk.Label(image_row, text="ğŸ–¼ï¸ å›¾åƒ:", bg='white', font=('Microsoft YaHei', 10, 'bold')).pack(side=tk.LEFT)
        
        ttk.Button(image_row, text="ğŸ“‚ é€‰æ‹©å•å¼ ", command=self.select_single_image, style='Success.TButton').pack(side=tk.LEFT, padx=10)
        ttk.Button(image_row, text="ğŸ“ æ‰¹é‡é€‰æ‹©", command=self.select_multiple_images, style='Success.TButton').pack(side=tk.LEFT, padx=5)
        ttk.Button(image_row, text="ğŸ—‚ï¸ é€‰æ‹©æ–‡ä»¶å¤¹", command=self.select_folder, style='Success.TButton').pack(side=tk.LEFT, padx=5)
        
        self.image_count_label = tk.Label(image_row, text="ğŸ“Š å·²é€‰æ‹©: 0 å¼ ", bg='white', font=('Microsoft YaHei', 9))
        self.image_count_label.pack(side=tk.LEFT, padx=20)
        
        # ç¬¬ä¸‰è¡Œï¼šå¤„ç†æŒ‰é’®
        process_row = tk.Frame(control_frame, bg='white')
        process_row.pack(fill=tk.X, pady=10)
        
        tk.Label(process_row, text="âš™ï¸ æ“ä½œ:", bg='white', font=('Microsoft YaHei', 10, 'bold')).pack(side=tk.LEFT)
        
        ttk.Button(process_row, text="ğŸš€ å¼€å§‹å¤„ç†", command=self.process_images, style='Primary.TButton').pack(side=tk.LEFT, padx=10)
        ttk.Button(process_row, text="ğŸ’¾ ä¿å­˜ç»“æœ", command=self.save_results).pack(side=tk.LEFT, padx=5)
        ttk.Button(process_row, text="ğŸ—‘ï¸ æ¸…é™¤", command=self.clear_results, style='Warning.TButton').pack(side=tk.LEFT, padx=5)
        
        # è†¨èƒ€æ ¸å¤§å°æç¤º
        dilation_info = tk.Label(process_row, text=f"ğŸ’¡ è†¨èƒ€æ ¸å¤§å°: {self.dilation_size} (å›ºå®š)", 
                                bg='white', font=('Microsoft YaHei', 9), fg=self.colors['info'])
        dilation_info.pack(side=tk.LEFT, padx=20)
    def create_image_panel(self, parent):
        """åˆ›å»ºå›¾åƒåˆ—è¡¨å’Œé¢„è§ˆé¢æ¿"""
        image_frame = ttk.LabelFrame(parent, text="ğŸ“· å›¾åƒç®¡ç†", style='Modern.TLabelframe', padding=10)
        image_frame.pack(fill=tk.X, pady=(0, 15))
        
        # å›¾åƒåˆ—è¡¨æ¡†
        list_frame = tk.Frame(image_frame, bg='white')
        list_frame.pack(fill=tk.X)
        
        # åˆ—è¡¨æ ‡é¢˜
        tk.Label(list_frame, text="å›¾åƒåˆ—è¡¨:", bg='white', font=('Microsoft YaHei', 10, 'bold')).pack(anchor=tk.W)
        
        # åˆ›å»ºåˆ—è¡¨æ¡†å’Œæ»šåŠ¨æ¡
        list_container = tk.Frame(list_frame, bg='white')
        list_container.pack(fill=tk.X, pady=5)
        
        self.image_listbox = tk.Listbox(list_container, height=4, font=('Consolas', 9),
                                       selectmode=tk.SINGLE, activestyle='dotbox')
        scrollbar = ttk.Scrollbar(list_container, orient=tk.VERTICAL, command=self.image_listbox.yview)
        self.image_listbox.configure(yscrollcommand=scrollbar.set)
        
        self.image_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # ç»‘å®šé€‰æ‹©äº‹ä»¶
        self.image_listbox.bind('<<ListboxSelect>>', self.on_image_select)
        
        # å›¾åƒæ“ä½œæŒ‰é’®
        image_ops_frame = tk.Frame(list_frame, bg='white')
        image_ops_frame.pack(fill=tk.X, pady=5)
        
        ttk.Button(image_ops_frame, text="ğŸ”¼ ä¸Šç§»", command=self.move_image_up).pack(side=tk.LEFT, padx=2)
        ttk.Button(image_ops_frame, text="ğŸ”½ ä¸‹ç§»", command=self.move_image_down).pack(side=tk.LEFT, padx=2)
        ttk.Button(image_ops_frame, text="âŒ ç§»é™¤", command=self.remove_selected_image, style='Warning.TButton').pack(side=tk.LEFT, padx=2)
        ttk.Button(image_ops_frame, text="ğŸ—‘ï¸ æ¸…ç©º", command=self.clear_image_list, style='Warning.TButton').pack(side=tk.LEFT, padx=2)
    
    def create_results_panel(self, parent):
        """åˆ›å»ºç»“æœæ˜¾ç¤ºé¢æ¿"""
        result_frame = ttk.LabelFrame(parent, text="ğŸ“Š å¤„ç†ç»“æœ", style='Modern.TLabelframe', padding=10)
        result_frame.pack(fill=tk.BOTH, expand=True)
        
        # åˆ›å»ºNotebookç”¨äºåˆ‡æ¢æ˜¾ç¤º
        self.notebook = ttk.Notebook(result_frame)
        self.notebook.pack(fill=tk.BOTH, expand=True)
        
        # åŸå›¾æ ‡ç­¾é¡µ
        self.original_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.original_frame, text="ğŸ–¼ï¸ åŸå§‹å›¾åƒ")
        
        # æ°´ä½“åˆ†å‰²æ ‡ç­¾é¡µ
        self.water_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.water_frame, text="ğŸŒŠ æ°´ä½“åˆ†å‰²")
        
        # æµ·å²¸çº¿æ ‡ç­¾é¡µ
        self.coastline_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.coastline_frame, text="ğŸ–ï¸ æµ·å²¸çº¿")
        
        # ç»¼åˆç»“æœæ ‡ç­¾é¡µ
        self.combined_frame = ttk.Frame(self.notebook)
        self.notebook.add(self.combined_frame, text="ğŸ“ˆ ç»¼åˆç»“æœ")
        
        # æ·»åŠ å›¾åƒå¯¼èˆªæ§åˆ¶
        nav_frame = tk.Frame(result_frame, bg='white', height=40)
        nav_frame.pack(fill=tk.X, pady=(10, 0))
        nav_frame.pack_propagate(False)
        
        ttk.Button(nav_frame, text="â—€ ä¸Šä¸€å¼ ", command=self.prev_image).pack(side=tk.LEFT, padx=10)
        
        self.image_nav_label = tk.Label(nav_frame, text="0 / 0", bg='white', font=('Microsoft YaHei', 10, 'bold'))
        self.image_nav_label.pack(side=tk.LEFT, padx=20)
        
        ttk.Button(nav_frame, text="ä¸‹ä¸€å¼  â–¶", command=self.next_image).pack(side=tk.LEFT, padx=10)
        
        # å›¾åƒæ§åˆ¶æŒ‰é’®
        control_frame = tk.Frame(nav_frame, bg='white')
        control_frame.pack(side=tk.RIGHT, padx=10)
        
        ttk.Button(control_frame, text="ğŸ”„ é‡ç½®ç¼©æ”¾", command=self.reset_all_zoom).pack(side=tk.LEFT, padx=2)
        ttk.Button(control_frame, text="ğŸ“ é€‚åº”çª—å£", command=self.fit_all_to_window).pack(side=tk.LEFT, padx=2)
        
        # ä½¿ç”¨è¯´æ˜
        help_label = tk.Label(nav_frame, text="ğŸ’¡ æ»šè½®ç¼©æ”¾ | å·¦é”®æ‹–æ‹½ | åŒå‡»é‡ç½®", 
                             bg='white', font=('Microsoft YaHei', 8), fg='gray')
        help_label.pack(side=tk.RIGHT, padx=20)
    
    def create_status_bar(self, parent):
        """åˆ›å»ºçŠ¶æ€æ """
        status_frame = tk.Frame(parent, bg=self.colors['light'], height=30)
        status_frame.pack(fill=tk.X, pady=(10, 0))
        status_frame.pack_propagate(False)
        
        self.status_var = tk.StringVar(value="ğŸš€ ç³»ç»Ÿå°±ç»ª")
        self.status_bar = tk.Label(status_frame, textvariable=self.status_var,
                                  bg=self.colors['light'], fg=self.colors['dark'],
                                  font=('Microsoft YaHei', 9), anchor=tk.W)
        self.status_bar.pack(fill=tk.X, padx=10, pady=5)
    
    def select_model(self):
        """é€‰æ‹©æ¨¡å‹æ–‡ä»¶"""
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©æ¨¡å‹æ–‡ä»¶",
            filetypes=[("PyTorchæ¨¡å‹", "*.pth"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.model_path.set(filename)
    
    def select_single_image(self):
        """é€‰æ‹©å•å¼ å›¾åƒ"""
        filename = filedialog.askopenfilename(
            title="é€‰æ‹©å›¾åƒæ–‡ä»¶",
            filetypes=[("å›¾åƒæ–‡ä»¶", "*.png *.jpg *.jpeg *.tif *.tiff"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filename:
            self.image_paths = [filename]
            self.update_image_list()
            self.current_image_index = 0
            self.is_batch_mode = False
    
    def select_multiple_images(self):
        """æ‰¹é‡é€‰æ‹©å¤šå¼ å›¾åƒ"""
        filenames = filedialog.askopenfilenames(
            title="æ‰¹é‡é€‰æ‹©å›¾åƒæ–‡ä»¶",
            filetypes=[("å›¾åƒæ–‡ä»¶", "*.png *.jpg *.jpeg *.tif *.tiff"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        if filenames:
            self.image_paths = list(filenames)
            self.update_image_list()
            self.current_image_index = 0
            self.is_batch_mode = len(filenames) > 1
    
    def select_folder(self):
        """é€‰æ‹©æ–‡ä»¶å¤¹æ‰¹é‡å¯¼å…¥å›¾åƒ"""
        folder = filedialog.askdirectory(title="é€‰æ‹©åŒ…å«å›¾åƒçš„æ–‡ä»¶å¤¹")
        if folder:
            # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒæ–‡ä»¶
            image_files = []
            for ext in ['*.png', '*.jpg', '*.jpeg', '*.tif', '*.tiff']:
                import glob
                image_files.extend(glob.glob(os.path.join(folder, ext)))
                image_files.extend(glob.glob(os.path.join(folder, ext.upper())))
            
            if image_files:
                self.image_paths = sorted(image_files)  # æ’åº
                self.update_image_list()
                self.current_image_index = 0
                self.is_batch_mode = len(image_files) > 1
            else:
                messagebox.showwarning("è­¦å‘Š", "æ‰€é€‰æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
    
    def update_image_list(self):
        """æ›´æ–°å›¾åƒåˆ—è¡¨æ˜¾ç¤º"""
        self.image_listbox.delete(0, tk.END)
        for i, path in enumerate(self.image_paths):
            filename = os.path.basename(path)
            self.image_listbox.insert(tk.END, f"{i+1:2d}. {filename}")
        
        self.image_count_label.config(text=f"ğŸ“Š å·²é€‰æ‹©: {len(self.image_paths)} å¼ ")
        self.update_nav_label()
        
        # å¦‚æœæœ‰å›¾åƒï¼Œé€‰ä¸­ç¬¬ä¸€å¼ 
        if self.image_paths:
            self.image_listbox.selection_set(0)
    
    def on_image_select(self, event):
        """å›¾åƒåˆ—è¡¨é€‰æ‹©äº‹ä»¶"""
        selection = self.image_listbox.curselection()
        if selection:
            self.current_image_index = selection[0]
            self.update_nav_label()
            # å¦‚æœå·²æœ‰ç»“æœï¼Œæ˜¾ç¤ºå¯¹åº”ç»“æœ
            if self.current_results and self.current_image_index < len(self.current_results):
                if self.current_results[self.current_image_index]:
                    self.display_results(self.current_results[self.current_image_index])
    
    def move_image_up(self):
        """ä¸Šç§»é€‰ä¸­çš„å›¾åƒ"""
        selection = self.image_listbox.curselection()
        if selection and selection[0] > 0:
            idx = selection[0]
            # äº¤æ¢ä½ç½®
            self.image_paths[idx], self.image_paths[idx-1] = self.image_paths[idx-1], self.image_paths[idx]
            if idx < len(self.current_results):
                self.current_results[idx], self.current_results[idx-1] = self.current_results[idx-1], self.current_results[idx]
            
            self.update_image_list()
            self.image_listbox.selection_set(idx-1)
            self.current_image_index = idx-1
    
    def move_image_down(self):
        """ä¸‹ç§»é€‰ä¸­çš„å›¾åƒ"""
        selection = self.image_listbox.curselection()
        if selection and selection[0] < len(self.image_paths) - 1:
            idx = selection[0]
            # äº¤æ¢ä½ç½®
            self.image_paths[idx], self.image_paths[idx+1] = self.image_paths[idx+1], self.image_paths[idx]
            if idx < len(self.current_results) - 1:
                self.current_results[idx], self.current_results[idx+1] = self.current_results[idx+1], self.current_results[idx]
            
            self.update_image_list()
            self.image_listbox.selection_set(idx+1)
            self.current_image_index = idx+1
    
    def remove_selected_image(self):
        """ç§»é™¤é€‰ä¸­çš„å›¾åƒ"""
        selection = self.image_listbox.curselection()
        if selection:
            idx = selection[0]
            del self.image_paths[idx]
            if idx < len(self.current_results):
                del self.current_results[idx]
            
            self.update_image_list()
            # è°ƒæ•´å½“å‰ç´¢å¼•
            if self.current_image_index >= len(self.image_paths):
                self.current_image_index = max(0, len(self.image_paths) - 1)
            
            if self.image_paths and self.current_image_index < len(self.image_paths):
                self.image_listbox.selection_set(self.current_image_index)
    
    def clear_image_list(self):
        """æ¸…ç©ºå›¾åƒåˆ—è¡¨"""
        self.image_paths = []
        self.current_results = []
        self.current_image_index = 0
        self.update_image_list()
        self.clear_results()
    
    def prev_image(self):
        """ä¸Šä¸€å¼ å›¾åƒ"""
        if self.image_paths and self.current_image_index > 0:
            self.current_image_index -= 1
            self.image_listbox.selection_clear(0, tk.END)
            self.image_listbox.selection_set(self.current_image_index)
            self.update_nav_label()
            if self.current_results and self.current_image_index < len(self.current_results):
                if self.current_results[self.current_image_index]:
                    self.display_results(self.current_results[self.current_image_index])
    
    def next_image(self):
        """ä¸‹ä¸€å¼ å›¾åƒ"""
        if self.image_paths and self.current_image_index < len(self.image_paths) - 1:
            self.current_image_index += 1
            self.image_listbox.selection_clear(0, tk.END)
            self.image_listbox.selection_set(self.current_image_index)
            self.update_nav_label()
            if self.current_results and self.current_image_index < len(self.current_results):
                if self.current_results[self.current_image_index]:
                    self.display_results(self.current_results[self.current_image_index])
    
    def update_nav_label(self):
        """æ›´æ–°å¯¼èˆªæ ‡ç­¾"""
        if self.image_paths:
            self.image_nav_label.config(text=f"{self.current_image_index + 1} / {len(self.image_paths)}")
        else:
            self.image_nav_label.config(text="0 / 0")
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆå¸¦å¼¹çª—æç¤ºï¼‰"""
        if not self.model_path.get():
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆé€‰æ‹©æ¨¡å‹æ–‡ä»¶")
            return
        
        try:
            self.status_var.set("æ­£åœ¨åŠ è½½æ¨¡å‹...")
            self.root.update()
            
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.extractor = CoastlineExtractor(self.model_path.get(), device=device)
            
            self.status_var.set(f"æ¨¡å‹å·²å°±ç»ª (è®¾å¤‡: {device}) | è†¨èƒ€æ ¸å¤§å°: {self.dilation_size}")
            self.model_status_label.config(text="âœ“ å·²åŠ è½½", foreground=self.colors['success'])
            print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path.get()}")
            print(f"âœ“ ä½¿ç”¨è®¾å¤‡: {device}")
            messagebox.showinfo("æˆåŠŸ", f"æ¨¡å‹åŠ è½½æˆåŠŸï¼\nè®¾å¤‡: {device}")
            
        except Exception as e:
            self.status_var.set("æ¨¡å‹åŠ è½½å¤±è´¥")
            self.model_status_label.config(text="âŒ å¤±è´¥", foreground=self.colors['warning'])
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            messagebox.showerror("é”™è¯¯", f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
    
    def process_images(self):
        """å¤„ç†å›¾åƒï¼ˆæ”¯æŒå•å¼ å’Œæ‰¹é‡ï¼‰"""
        if not self.extractor:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆåŠ è½½æ¨¡å‹")
            return
        
        if not self.image_paths:
            messagebox.showerror("é”™è¯¯", "è¯·å…ˆé€‰æ‹©å›¾åƒæ–‡ä»¶")
            return
        
        def process_thread():
            try:
                self.current_results = []
                total_images = len(self.image_paths)
                
                for i, image_path in enumerate(self.image_paths):
                    # æ›´æ–°çŠ¶æ€
                    progress_text = f"æ­£åœ¨å¤„ç†å›¾åƒ {i+1}/{total_images}: {os.path.basename(image_path)}"
                    self.status_var.set(progress_text)
                    self.root.update()
                    
                    print(f"\nğŸ”„ {progress_text}")
                    
                    # æå–æµ·å²¸çº¿
                    result = self.extractor.extract_coastline_from_image(
                        image_path,
                        dilation_size=self.dilation_size
                    )
                    
                    self.current_results.append(result)
                    
                    if result:
                        print(f"âœ“ å®Œæˆ - æ‰¾åˆ° {result['coastline_count']} æ¡æµ·å²¸çº¿")
                        
                        # å¦‚æœæ˜¯å½“å‰æ˜¾ç¤ºçš„å›¾åƒï¼Œç«‹å³æ›´æ–°æ˜¾ç¤º
                        if i == self.current_image_index:
                            self.display_results(result)
                    else:
                        print("âŒ å¤„ç†å¤±è´¥")
                
                # å¤„ç†å®Œæˆ
                successful_count = sum(1 for r in self.current_results if r is not None)
                
                if self.is_batch_mode:
                    self.status_var.set(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ - æˆåŠŸ: {successful_count}/{total_images}")
                    print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {successful_count}/{total_images} å¼ å›¾åƒ")
                else:
                    if successful_count > 0:
                        result = self.current_results[0]
                        self.status_var.set(f"âœ… å¤„ç†å®Œæˆ - æ‰¾åˆ° {result['coastline_count']} æ¡æµ·å²¸çº¿")
                        print(f"ğŸ‰ å¤„ç†å®Œæˆï¼æ‰¾åˆ° {result['coastline_count']} æ¡æµ·å²¸çº¿")
                    else:
                        self.status_var.set("âŒ å¤„ç†å¤±è´¥")
                        print("âŒ å¤„ç†å¤±è´¥")
                
                # æ˜¾ç¤ºå½“å‰å›¾åƒçš„ç»“æœ
                if (self.current_results and self.current_image_index < len(self.current_results) 
                    and self.current_results[self.current_image_index]):
                    self.display_results(self.current_results[self.current_image_index])
                
            except Exception as e:
                self.status_var.set(f"âŒ å¤„ç†å‡ºé”™: {str(e)}")
                print(f"âŒ å¤„ç†å‡ºé”™: {str(e)}")
                messagebox.showerror("é”™è¯¯", f"å¤„ç†å‡ºé”™: {str(e)}")
        
        # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†
        import threading
        threading.Thread(target=process_thread, daemon=True).start()
    
    def display_results(self, result):
        """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
        try:
            # åŠ è½½åŸå›¾ï¼ˆç”¨äºæ˜¾ç¤ºï¼Œä¸åº”ç”¨æ°´ä½“å¢å¼ºï¼‰
            if result['image_path'].lower().endswith(('.tif', '.tiff')):
                original_image = self.extractor.load_tif_image_for_display(result['image_path'])
            else:
                original_image = Image.open(result['image_path'])
            
            # è°ƒæ•´å›¾åƒå¤§å°ä»¥é€‚åº”æ˜¾ç¤º
            max_size = (600, 400)
            original_image.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # æ˜¾ç¤ºåŸå›¾
            self.display_image_in_frame(original_image, self.original_frame, "åŸå§‹å›¾åƒ")
            
            # åˆ›å»ºæ°´ä½“åˆ†å‰²æ˜¾ç¤ºï¼ˆè“è‰²ï¼‰
            water_display = self.create_water_display(result, original_image.size)
            self.display_image_in_frame(water_display, self.water_frame, "æ°´ä½“åŒºåŸŸï¼ˆè“è‰²ï¼‰")
            
            # åˆ›å»ºæµ·å²¸çº¿æ˜¾ç¤ºï¼ˆç™½è‰²ï¼‰
            coastline_display = self.create_coastline_display(result, original_image.size)
            self.display_image_in_frame(coastline_display, self.coastline_frame, "æµ·å²¸çº¿ï¼ˆç™½è‰²ï¼‰")
            
            # åˆ›å»ºç»¼åˆæ˜¾ç¤º
            combined_display = self.create_combined_display(result, original_image)
            self.display_image_in_frame(combined_display, self.combined_frame, 
                                      f"ç»¼åˆç»“æœ\\næ°´ä½“ï¼ˆè“è‰²ï¼‰+ æµ·å²¸çº¿ï¼ˆç™½è‰²ï¼‰")
            
        except Exception as e:
            messagebox.showerror("æ˜¾ç¤ºé”™è¯¯", f"æ˜¾ç¤ºç»“æœæ—¶å‡ºé”™: {str(e)}")
    
    def create_water_display(self, result, display_size):
        """åˆ›å»ºæ°´ä½“åˆ†å‰²æ˜¾ç¤ºå›¾åƒ"""
        # è°ƒæ•´maskå°ºå¯¸
        water_mask = cv2.resize(result['water_mask'], display_size, interpolation=cv2.INTER_NEAREST)
        
        # åˆ›å»ºè“è‰²æ°´ä½“å›¾åƒ
        water_image = np.zeros((*water_mask.shape, 3), dtype=np.uint8)
        water_image[water_mask == 1] = [0, 0, 255]  # è“è‰²
        
        return Image.fromarray(water_image)
    
    def create_coastline_display(self, result, display_size):
        """åˆ›å»ºæµ·å²¸çº¿æ˜¾ç¤ºå›¾åƒ"""
        # è°ƒæ•´maskå°ºå¯¸
        coastline_mask = cv2.resize(result['coastline_mask'], display_size, interpolation=cv2.INTER_NEAREST)
        
        # åˆ›å»ºç™½è‰²æµ·å²¸çº¿å›¾åƒ
        coastline_image = np.zeros((*coastline_mask.shape, 3), dtype=np.uint8)
        coastline_image[coastline_mask == 1] = [255, 255, 255]  # ç™½è‰²
        
        return Image.fromarray(coastline_image)
    
    def create_combined_display(self, result, original_image):
        """åˆ›å»ºç»¼åˆæ˜¾ç¤ºå›¾åƒ"""
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        combined = np.array(original_image.copy())
        
        # è°ƒæ•´maskå°ºå¯¸
        display_size = original_image.size
        water_mask = cv2.resize(result['water_mask'], display_size, interpolation=cv2.INTER_NEAREST)
        coastline_mask = cv2.resize(result['coastline_mask'], display_size, interpolation=cv2.INTER_NEAREST)
        
        # å åŠ æ°´ä½“åŒºåŸŸï¼ˆè“è‰²åŠé€æ˜ï¼‰
        water_coords = np.where(water_mask == 1)
        combined[water_coords[0], water_coords[1]] = combined[water_coords[0], water_coords[1]] * 0.7 + np.array([0, 0, 255]) * 0.3
        
        # å åŠ æµ·å²¸çº¿ï¼ˆç™½è‰²ï¼‰
        coastline_coords = np.where(coastline_mask == 1)
        combined[coastline_coords[0], coastline_coords[1]] = [255, 255, 255]
        
        return Image.fromarray(combined.astype(np.uint8))
    
    def display_image_in_frame(self, image, frame, title):
        """åœ¨æŒ‡å®šæ¡†æ¶ä¸­æ˜¾ç¤ºå›¾åƒ - æ”¯æŒç¼©æ”¾å’Œæ‹–æ‹½"""
        # æ¸…é™¤æ¡†æ¶ä¸­çš„æ—§å†…å®¹
        for widget in frame.winfo_children():
            widget.destroy()
        
        # åˆ›å»ºå¯ç¼©æ”¾æ‹–æ‹½çš„å›¾åƒæŸ¥çœ‹å™¨
        image_viewer = ZoomableImageCanvas(frame, image)
        image_viewer.pack(fill=tk.BOTH, expand=True)
    
    def save_results(self):
        """ä¿å­˜ç»“æœï¼ˆæ”¯æŒæ‰¹é‡ä¿å­˜ï¼‰"""
        if not self.current_results or not any(self.current_results):
            messagebox.showerror("é”™è¯¯", "æ²¡æœ‰å¯ä¿å­˜çš„ç»“æœ")
            return
        
        output_dir = filedialog.askdirectory(title="é€‰æ‹©ä¿å­˜ç›®å½•")
        if output_dir:
            try:
                saved_count = 0
                for i, result in enumerate(self.current_results):
                    if result:
                        # ä¸ºæ¯ä¸ªç»“æœåˆ›å»ºå­ç›®å½•
                        image_name = os.path.splitext(os.path.basename(result['image_path']))[0]
                        result_dir = os.path.join(output_dir, f"{i+1:03d}_{image_name}")
                        
                        self.extractor.save_extraction_result(result, result_dir)
                        saved_count += 1
                        print(f"âœ“ å·²ä¿å­˜: {result_dir}")
                
                if self.is_batch_mode:
                    messagebox.showinfo("æˆåŠŸ", f"æ‰¹é‡ä¿å­˜å®Œæˆï¼\næˆåŠŸä¿å­˜ {saved_count} ä¸ªç»“æœåˆ°: {output_dir}")
                else:
                    messagebox.showinfo("æˆåŠŸ", f"ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
                    
                print(f"ğŸ‰ ä¿å­˜å®Œæˆï¼å…±ä¿å­˜ {saved_count} ä¸ªç»“æœ")
                
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜å¤±è´¥: {str(e)}")
                print(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
    
    def clear_results(self):
        """æ¸…é™¤ç»“æœ"""
        self.current_results = []
        
        # æ¸…é™¤æ‰€æœ‰æ˜¾ç¤ºæ¡†æ¶
        for frame in [self.original_frame, self.water_frame, self.coastline_frame, self.combined_frame]:
            for widget in frame.winfo_children():
                widget.destroy()
        
        self.status_var.set("ğŸ—‘ï¸ å·²æ¸…é™¤ç»“æœ")
        print("ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰ç»“æœ")
    
    def reset_all_zoom(self):
        """é‡ç½®æ‰€æœ‰å›¾åƒçš„ç¼©æ”¾"""
        for frame in [self.original_frame, self.water_frame, self.coastline_frame, self.combined_frame]:
            for widget in frame.winfo_children():
                if isinstance(widget, ZoomableImageCanvas):
                    widget.reset_zoom()
    
    def fit_all_to_window(self):
        """è®©æ‰€æœ‰å›¾åƒé€‚åº”çª—å£å¤§å°"""
        for frame in [self.original_frame, self.water_frame, self.coastline_frame, self.combined_frame]:
            for widget in frame.winfo_children():
                if isinstance(widget, ZoomableImageCanvas):
                    widget.fit_to_window()
            for widget in frame.winfo_children():
                if isinstance(widget, ZoomableImageCanvas):
                    widget.fit_to_window()

def main():
    """ä¸»å‡½æ•° - é»˜è®¤å¯åŠ¨å›¾å½¢ç•Œé¢"""
    print("=" * 60)
    print("ğŸŒŠ æµ·æ°´åŒºåŸŸåˆ†å‰²ä¸æµ·å²¸çº¿æå–ç³»ç»Ÿ v2.0")
    print("CoastSat Enhanced Edition")
    print("=" * 60)
    
    try:
        # ç›´æ¥å¯åŠ¨å›¾å½¢ç•Œé¢
        print("ğŸš€ å¯åŠ¨å›¾å½¢ç•Œé¢...")
        
        try:
            import tkinter as tk
            root = tk.Tk()
            app = CoastlineGUI(root)
            
            print("âœ… å›¾å½¢ç•Œé¢å¯åŠ¨æˆåŠŸï¼")
            print("ğŸ’¡ æç¤ºï¼š")
            print("  - é»˜è®¤è†¨èƒ€æ ¸å¤§å°å·²è®¾ä¸º 20")
            print("  - æ”¯æŒå•å¼ å’Œæ‰¹é‡å›¾åƒå¤„ç†")
            print("  - ä¼šè‡ªåŠ¨å°è¯•åŠ è½½é»˜è®¤æ¨¡å‹")
            print("  - ç•Œé¢å·²ä¼˜åŒ–ä¸ºç°ä»£å·¥ä¸šé£æ ¼")
            print("=" * 60)
            
            root.mainloop()
            
        except ImportError:
            print("âŒ GUIå¯åŠ¨å¤±è´¥ï¼šç¼ºå°‘tkinteråº“")
            print("è¯·å®‰è£…tkinter: pip install tk")
            
            # æä¾›å‘½ä»¤è¡Œæ›¿ä»£é€‰é¡¹
            print("\nğŸ”„ è½¬ä¸ºå‘½ä»¤è¡Œæ¨¡å¼...")
            command_line_interface()
            
        except Exception as e:
            print(f"âŒ GUIå¯åŠ¨å¤±è´¥: {e}")
            print("\nï¿½ è½¬ä¸ºå‘½ä»¤è¡Œæ¨¡å¼...")
            command_line_interface()
    
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")

def command_line_interface():
    """å‘½ä»¤è¡Œç•Œé¢ï¼ˆå¤‡ç”¨é€‰é¡¹ï¼‰"""
    print("\n" + "=" * 50)
    print("ğŸ“‹ å‘½ä»¤è¡Œæ¨¡å¼")
    print("=" * 50)
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. å•å¼ å›¾åƒå¤„ç†")
        print("2. æ‰¹é‡å¤„ç†")
        print("3. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
        
        if choice == '1':
            # å•å¼ å›¾åƒå¤„ç†
            print("\n=== å•å¼ å›¾åƒå¤„ç† ===")
            model_path = input("è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./models/best_water_segmentation_model.pth): ").strip()
            if not model_path:
                model_path = "./models/best_water_segmentation_model.pth"
            
            if not os.path.exists(model_path):
                print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                continue
            
            image_path = input("è¯·è¾“å…¥å›¾åƒæ–‡ä»¶è·¯å¾„: ").strip()
            if os.path.exists(image_path):
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
                print(f"ä½¿ç”¨è®¾å¤‡: {device}")
                
                extractor = CoastlineExtractor(model_path=model_path, device=device)
                
                print("æ­£åœ¨å¤„ç†å›¾åƒ...")
                result = extractor.extract_coastline_from_image(
                    image_path,
                    output_dir="./coastline_results",
                    dilation_size=20  # é»˜è®¤è†¨èƒ€æ ¸å¤§å°
                )
                
                if result:
                    print(f"\n=== å¤„ç†å®Œæˆ ===")
                    print(f"æ‰¾åˆ° {result['coastline_count']} æ¡æµ·å²¸çº¿")
                    print(f"å›¾åƒå°ºå¯¸: {result['image_size']}")
                    print(f"è†¨èƒ€æ ¸å¤§å°: {result['dilation_size']}")
                    print(f"ç»“æœä¿å­˜åœ¨: ./coastline_results")
                else:
                    print("âŒ å›¾åƒå¤„ç†å¤±è´¥")
            else:
                print("âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨")
        
        elif choice == '2':
            # æ‰¹é‡å¤„ç†
            print("\n=== æ‰¹é‡å¤„ç†åŠŸèƒ½ ===")
            model_path = input("è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./models/best_water_segmentation_model.pth): ").strip()
            if not model_path:
                model_path = "./models/best_water_segmentation_model.pth"
            
            if not os.path.exists(model_path):
                print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                continue
            
            images_dir = input("è¯·è¾“å…¥å›¾åƒç›®å½•è·¯å¾„: ").strip()
            if not os.path.exists(images_dir):
                print("âŒ ç›®å½•ä¸å­˜åœ¨")
                continue
            
            output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: ./batch_results): ").strip()
            if not output_dir:
                output_dir = "./batch_results"
            
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            extractor = CoastlineExtractor(model_path=model_path, device=device)
            
            # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
            import glob
            image_files = []
            for ext in ['*.png', '*.jpg', '*.jpeg', '*.tif', '*.tiff']:
                image_files.extend(glob.glob(os.path.join(images_dir, ext)))
                image_files.extend(glob.glob(os.path.join(images_dir, ext.upper())))
            
            print(f"\næ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
            
            for i, image_path in enumerate(image_files, 1):
                print(f"\nå¤„ç† {i}/{len(image_files)}: {os.path.basename(image_path)}")
                
                result = extractor.extract_coastline_from_image(
                    image_path,
                    output_dir=output_dir,
                    dilation_size=20  # é»˜è®¤è†¨èƒ€æ ¸å¤§å°
                )
                
                if result:
                    print(f"  -> æ‰¾åˆ° {result['coastline_count']} æ¡æµ·å²¸çº¿")
                else:
                    print("  -> å¤„ç†å¤±è´¥")
            
            print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
        
        elif choice == '3':
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main()
